---
layout: post
title: "How to design experiments for people"
categories: posts
comments: true
tags: [methodology]
image:
  feature: tools.jpg
  teaser: tools-teaser.jpg
  credit:
  creditlink:
---

Over the course of my PhD, I came to the realization that running scientific experiments with human beings was awfully difficult. Biologists never have to deal with rats starting to play on their phone during a test, physicists seldom cancel a collider session because the protons showed up drunk and no one has ever seen an engineer blaming a failed launch test on the reagents falling asleep. However, this is the kind of stuff experimental psychologists and neuroscientists face on a daily basis. 

It is true that people can be unpredictable and temperamental, but this doesn’t make them an impossible research subject. This is actually what makes cognitive science so interesting : how do you extract facts from the seemingly chaotic human nature? The answer is : with a tightly controlled experimental setup. But designing such a research tool can be cumbersome. You want to control every parameters, but you have to keep in mind that actual human beings will have to run the experiment in the end.

Many times I came up with ideas that went to trash because I forgot about that. Either the task was too complicated, or too long, or too boring. I also lost considerable amount of time recruiting participants who did not show up on time, or simply disappeared in the nature. At first, I blamed it on bad luck or human nature, but after a while I figured out that some of these issues could be solved with a few design tweaks and a good amount of social engineering.

Usually these tricks are only discussed at the department’s coffee machine. It’s almost never part of the scientific discussion and it rarely makes it to the method section of research papers (because it's mundane, I guess). But if you are starting your researcher training and if you are pretty much on your own, I think you might learn something here. 

#### Disclaimer

* My advices are meant to improve data collection. It will not make any difference in the results of your experiment if you hypothesis are wrong in the first place. 

* These tips do not apply to all kind of experiments. If it induces or not a confound into your design is entirely up to you.

* These tips are not an excuse not to respect the [Helsinki Declaration](http://www.who.int/bulletin/archives/79(4)373.pdf). It’s not 1955 anymore, and you cannot do whatever you want with your participants. Let me remind you for instance that your participant can leave the experiment at any moment and that he should give an informed consent *before* running the experiment. You knew about that, right?

Now we can talk.

#### Pilot the damn thing properly

Before even thinking about running a full fledged experiment, run a pilot experiment. The goal of a good pilot is to break the experiment as many times as possible. Don’t slam the computer screen already, that’s not what I meant! The point of the pilot is to help you anticipate all the behaviors that might lead your computer program (or any other device used during the experiment) to freeze and crash. 

Contrarily to pure code debugging, this implies that you consider *human debugging* as well, that is all the potential human errors occurring during your experiment. Press all the keys at once, spin the mouse, try to unplug the screen HDMI cable with your feet, etc. If you can break it, you have to make it stronger. Remember that everyone is not necessarily familiar with a lab setting, and a lot of problems can occurs because scientists tend to forget about that. If you find a bug, fix it.

Once you got that straight, run the entire thing for yourself. This is a pain in the ass, I know. Your eyes are already bleeding and you have other important things to do, but do it anyway. Pay loads of attention to you data output : if you cannot read it, you’ve done all of this for nothing. 

Then, finally, test your fellow colleagues. It is really important to get a feedback from experienced people, even if you thought about everything (you didn’t). If the seat is broken, if the screen is blinking, if your program skips a few frames here and there, they will tell you. As long as you help other people piloting their own experiments, there is no shame in asking feedback at that point. Researchers know that.

Once you got that straight, you are ready to go.

#### Double screening

If you want to make sure that everything is going to run smoothly on the day of the experiment, you should already consider the recruitment process as part of the test. And reflecting on your recruitment routines is also part of good design practices. If you are lucky enough to work with an assistant (or if you have an army of undergrads at your orders because you work in Germany or something), you might not know about the joy of scheduling an appointment with people you don’t know. But if you do, you may have noticed that a lot happens at that stage.

The first thing you want to do is to screen your participants. You have to make sure that you will not include in your sample people with conditions or traits that might interfere with your procedure. That’s why you include a statement about the conditions for participating in your experiments within your recruitment email, then you make an appointment with those who answer. I’m sure you know about all of this already, I should not even mention it.

But this is where *double screening* trick comes into play. Rather than making an appointment right away ask for more informations in a second email. Eventually, send a form to fill with additional details. Then only makes an appointment upon completion of the form, even if the informations you asked were absolutely pointless for the task. 

I noticed that many potential applicants drop out at this stage and never answer the second email. Probably because they are busy or too lazy to provide further details, I don’t know. But this is a good thing, because that means they would have been likely to cause more problems later in the process. On top of luring potential lazy participants, this trick allows you to keep informations about the participants that might be useful later (age, gender, etc.) in case you forget to ask them on the day of the experiment. 

But remember that you are not allowed to store personal details about people for an extended period of time (even if they agreed on giving you that information). Always use a secure email account when communicating with your participants and delete everything once the experiment is done.

#### Be precise

Make sure to explain your task as clearly as possible, in a systematic manner. I suggest you to use a cheat sheet that you’ll leave by the participant for the experiment. The sheet will help you make sure that you don’t skip any details and that you provide each participant with the same information. If the participant has a doubt during the experiment, he can still refer to the sheet if you’re not around to answer the question. 

Try to make your explanations as concise as possible, using visuals rather than text. Pictures facilitate the comprehension of the task and are easier to discriminate in a dark environment.
I also strongly advise you to run a dummy block of trial with the participant. This is a good way to correct potential errors before the actual experiment begins.

#### Provide feedback

A lot of the task I ran were extremely boring. People had to press random keys, and were asked to pay close attention to the stimulus elicited by the key press. Nothing interesting happened, it was just colored squares or neutral tones. In order to keep participants engaged into this task, I added a point system on top of it. For each successful trial, they would get one point and see how much they got during breaks. The points did not represent anything, but nevertheless people were interested in how good they did and how they could get better from block to block. You can also take advantage of [loss aversion](http://www3.uah.es/econ/MicroDoct/Tversky_Kahneman_1991_Loss%20aversion.pdf) to implement a system where participants can only lose points in case of mistake. 

But the goal of this design trick is not to merely “gamify” your experiment. Including a point system is part of the broader process of providing constant feedback to your participants. Because people always seek information in order to adjust their behavior, they need to know how well they perform to keep interested in the task. If you leave them without a clue, they will quickly start thinking that the experiment is pointless. 

Additionally, counting participant’s mistakes over the course of the experiment is a good way to identify your participant’s learning curve. You can use that information to spot moments in the task where participants did very poorly, and start trying to find out why.

#### Be there

Never leave a participant alone for the whole experiment! First because you have to make sure that your participant is all right – that goes without saying – but you also want to check on him for potential questions or misunderstandings. Don’t expect your participant to fetch you in your office if he has a question after the first block, most of the time he will run the entire experiment without understanding the task fully and your data will be garbage.

Showing that you are paying attention is also a good way to catch participants sleeping or playing on their phone. Think about that too.

#### Wrapping it up

Running experiment with people is a complicated matter. It requires you to make compromises between the purity of your expectations and the reality of human nature. This is an humbling process where science meets craftsmanship. And like any other craft, it demands patience and skill.

Here I tried to communicate a few things I learned along the way. The common idea behind these tips is the necessity of putting human nature at the center of your design practices. It is tempting to dismiss it as trivial, but I think it would be a mistake. Denying the obvious in these circumstances is an excellent way to collect bad data. 

Finally, I think that these tips, and good practices in general, are always worth sharing regardless of your research or work field. If you have similar experience or useful tricks, feel free to share it in the comment section! 